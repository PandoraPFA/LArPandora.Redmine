BEGIN_PROLOG

pandora_event_dump:
{
    module_type: "LArPandoraEventDump"
}

dump_allHit_CR:                    @local::pandora_event_dump
dump_allHit_CR.PandoraLabel:       "pandoraAllHitCRHypothesis"
dump_allHit_CR.TrackLabel:         "pandoraAllHitCRHypothesisTrack"
dump_allHit_CR.ShowerLabel:        "pandoraAllHitCRHypothesisShower"

dump_crRemHit_CR:                  @local::pandora_event_dump
dump_crRemHit_CR.PandoraLabel:     "pandoraSlicesCRHypothesis"
dump_crRemHit_CR.TrackLabel:       "pandoraSlicesCRHypothesisTrack"
dump_crRemHit_CR.ShowerLabel:      "pandoraSlicesCRHypothesisShower"

dump_crRemHit_Nu:                  @local::pandora_event_dump
dump_crRemHit_Nu.PandoraLabel:     "pandoraSlicesNuHypothesis"
dump_crRemHit_Nu.TrackLabel:       "pandoraSlicesNuHypothesisTrack"
dump_crRemHit_Nu.ShowerLabel:      "pandoraSlicesNuHypothesisShower"

dump_cosmic:                       @local::pandora_event_dump
dump_cosmic.PandoraLabel:          "pandoraConsolidatedCosmic"

dump_nu:                           @local::pandora_event_dump
dump_nu.PandoraLabel:              "pandoraConsolidatedNu"

END_PROLOG



## 
##  Shared art job configuartions for MCC8 uboone reco
##
#include "services_microboone.fcl"
#include "time_memory_tracker_microboone.fcl"

services:
{
  scheduler:               { defaultExceptions: false }    # Make all uncaught exceptions fatal.
  # Load the service that manages root files for histograms.
  TFileService:            { fileName: "nah.root" }
  TimeTracker:             @local::microboone_time_tracker
  MemoryTracker:           @local::microboone_memory_tracker
  RandomNumberGenerator:   {} #ART native random number generator
  message:                 @local::microboone_message_services_prod_debug
  FileCatalogMetadata:     @local::art_file_catalog_mc
}

process_name: LArPandoraMergingTest

#source is a root file
source:
{
  module_type: RootInput
  maxEvents:  10        # Number of events to create
  saveMemoryObjectThreshold: 0
}

# Define and configure some modules to do work on each event.
# First modules are defined; they are scheduled later.
# Modules are grouped by type.
physics:
{

 analyzers:
 {
    # Dump information on the reconstruction of all hits as a cosmic ray
    dumpAll:          @local::dump_allHit_CR
    
    # Dump information on the reconstruction of the CR removed hits under both hypotheses
    dumpSliceCosmic:  @local::dump_crRemHit_CR
    dumpSliceNu:      @local::dump_crRemHit_Nu

    # Dump information on the merged collections
    dumpCosmic:       @local::dump_cosmic
    dumpNu:           @local::dump_nu
 }

 #reco sequence and trigger_paths to be defined elsewhere

 stream1:   [ dumpAll, dumpSliceCosmic, dumpSliceNu, dumpCosmic, dumpNu  ]
 end_paths: [ stream1 ]  

}

#block to define where the output goes.  if you defined a filter in the physics
#block and put it in the trigger_paths then you need to put a SelectEvents: {SelectEvents: [XXX]}
#entry in the output stream you want those to go to, where XXX is the label of the filter module(s)
outputs:
{
 out1:
 {
   module_type: RootOutput
   dataTier: "reconstructed"
   compressionLevel: 1
   saveMemoryObjectThreshold: 0
 }
}
